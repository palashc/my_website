<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Systems | Palash Chauhan</title>
    <link>/tags/systems/</link>
      <atom:link href="/tags/systems/index.xml" rel="self" type="application/rss+xml" />
    <description>Systems</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 11 Mar 2020 00:00:00 -0700</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Systems</title>
      <link>/tags/systems/</link>
    </image>
    
    <item>
      <title>osbench</title>
      <link>/project/os/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 -0700</pubDate>
      <guid>/project/os/</guid>
      <description>&lt;p&gt;osbench is a micro-benchmark study of analyzing the major set of operations in the Ubuntu operating system. We isolate and perform experiments for four kinds of operations in an operating system - CPU, Memory, Network and File System. Prior to running experiments, we make calculated predictions for each operation based on hardware estimates found in documentations or using our own judgement. We present the results of our experiments and also compare them against our predictions. Overall, the study helped us gain an understanding of the relative performance of different basic operations and will help us identify performance bottlenecks in the systems we build in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Serverless Networking</title>
      <link>/project/hole-punch/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 -0700</pubDate>
      <guid>/project/hole-punch/</guid>
      <description>&lt;p&gt;Serverless is an emerging paradigm for the deployment of applications and services, influenced by the recent shift towards containers and microservices. Serverless function provides a simplified programming model for creating cloud applications and abstracts away most of the operational concerns. However, it lacks one important component needed to unlock its complete potential - communication. In the latest offering of Function-as-a-Service platform, two serverless functions can only communicate with each other through an intermediary storage service like S3 since the functions are not directly network-addressable. This approach is slower and adds extra cost for the cloud consumer. In this project, we explore an alternative means to achieve serverless communication - NAT Hole Punching. We analyze the feasibility of the approach for various scenarios of serverless function placement in the context of AWS network infrastructure, and evaluate the mechanism on some micro- and macro-benchmarks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking Druid and Presto</title>
      <link>/project/drupre/</link>
      <pubDate>Sun, 29 Dec 2019 15:21:34 -0800</pubDate>
      <guid>/project/drupre/</guid>
      <description>&lt;p&gt;In recent years, the proliferation of internet technology has created a surge in machine generated events. These events generally have three parts – timestamp, dimensions and metrics. For example – advertising impression data with dimensions like publisher, gender, country etc and metrics like clicks, price etc. Individually these events contain minimal useful information and are of low value. Earlier, companies were willing to discard this data due to the time and resources required to extract any meaning out of it. But now, big data technology such as Hadoop has contributed much to helping companies convert their low value event streams to high value aggregates for a variety of applications.&lt;/br&gt;&lt;/br&gt;However, Hadoop opens our eyes to new problems. Hadoop is a great batch-processing and data warehousing system but it does not make any performance guarantees and its performance degrades under concurrent workload. If a product’s use case needs guarantees around query performance and data availability in a highly concurrent environment, Hadoop is certainly not going to meet the needs. Using an RDBMS like MySQL or Postgres is not an option since data might be stored in a star schema which will lead to operational overhead and table-scan operations (global counts) will be very slow. Another option is to pre-compute aggregates for all possible combinations of dimensions and store them in a key-value NoSQL store. However, the time required to pre-compute aggregates will increase exponentially with the number of dimensions. While working in the Infrastructure Team at Adobe Media Optimizer, I had to evaluate other big data systems for a similar use-case.&lt;/br&gt;&lt;/br&gt;Druid is a distributed column-oriented real-time analytical data store which has a parallelized architecture and is optimized for OLAP workflows.&lt;/br&gt;&lt;/br&gt;Presto is a distributed SQL query engine designed to query large data sets distributed over one or more heterogeneous data sources.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SurfStore</title>
      <link>/project/raft/</link>
      <pubDate>Sun, 29 Dec 2019 15:20:45 -0800</pubDate>
      <guid>/project/raft/</guid>
      <description>&lt;p&gt;Getting people to agree on something is hard. Getting machines connected through an asychronous network to agree on something is harder. RAFT is an easy-to-understand consensus protocol which uses leader election and log replication to achieve consensus. In this project, a cloud-based file storage system was built that can survive server failure, datacenter failure, and network failures. Leader election and log replication from the RAFT Consensus protocol were implemented to maintain a consistent state across servers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comparing Virtualization Techniques</title>
      <link>/project/cloud/</link>
      <pubDate>Tue, 10 Dec 2019 00:00:00 -0800</pubDate>
      <guid>/project/cloud/</guid>
      <description>&lt;p&gt;We performed an in-depth analysis of Virtual Machines, Containers and Serverless using two different CPU-bound and IO-bound applications. We can conclude the following observations from our analysis - (i) Serverless is the most convenient for deploying and maintaining an application closely followed by Containers. The deploy- ment is much slower for Virtual Machines. (ii) For dif- ferent types of workloads, Containers give a better per- formance and scalability compared to Virtual Machines and Serverless. (iii) From a monetary standpoint, Server- less and Containers are cheaper compared to Virtual Ma- chines for smaller workloads, but Containers are the best option for larger workloads. Containers and Virtual ma- chine are more suitable for building services which need to be always online so as to avoid the overhead of load- ing the state in Serverless. Our study and the results have helped us understand the various dimensions of deploy- ing applications in the cloud and we will be able to take an informed decision in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Load Value Prediction</title>
      <link>/project/lvp/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 -0700</pubDate>
      <guid>/project/lvp/</guid>
      <description>&lt;p&gt;Data dependencies can severely hinder Instruction Level Parallelism (ILP). Data dependencies decrease ILP when long latency instructions flow through the pipeline, and there are not enough independent instructions available to keep the processor busy. Data dependent instructions will stall behind these long latency instructions, potentially creating one or several critical paths through a portion of the program. Load Value Prediction (LVP) is an approach that breaks data dependency on load instructions by predicting the value which is fetched by the instruction. LVP exploits value locality which can be defined as the likelihood of a previously-seen value recurring repeatedly within a storage location. In this project, we explore this notion of value locality, exploit it in order to perform load value prediction and analyze the performance on SPEC2006 Benchmarks.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
